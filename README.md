## ðŸ§© Build a Dummy ChatGPT Model from Scratch

This project is an educational implementation of a simplified ChatGPT-like model built entirely from scratch using PyTorch. The project covers everything from implementing the Transformer architecture manually to fine-tuning the model into a small-scale LLM for spam vs. non-spam classification.

Features :- 
- Implemented Transformer components from scratch:
  - Multi-Head Attention
  - Position-Wise Feed Forward Networks
  - Positional Encoding
  - Encoder & Decoder Stacks

- Trained a dummy GPT-like language model on sample text data.
- Fine-tuned the model to classify messages into Spam or Non-Spam.
- End-to-end PyTorch implementation (no pre-built Hugging Face Transformers).

## Results
- Pretraining: Model learns basic next-token prediction.
- Fine-tuning: Model achieves good accuracy in distinguishing spam vs. non-spam.
